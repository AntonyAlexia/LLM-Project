# LLM-Project

This project is a smart FAQ system that takes text from a PDF and makes it easy to search for relevant answers. First, it uses the `fitz` library to pull all the text from the PDF. Then, it creates frequently asked questions (FAQs) from that text using OpenAI’s language model through LangChain, which helps identify questions and answers based on the document’s content. To make searching efficient, each FAQ is converted into an “embedding”—a numerical representation of its meaning—so similar questions can match even with different wording. These embeddings are stored in Pinecone, a vector database that allows quick and accurate searches. When someone asks a question, the project searches for similar FAQ embeddings and retrieves the most relevant answers. Finally, an enhanced answer is provided using a technique called Retrieval-Augmented Generation (RAG), combining the best-matching FAQ with a clear response. This setup makes it ideal for turning any document into an interactive FAQ system.
